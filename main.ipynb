{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f600608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade pip\n",
    "# %pip install --disable-pip-version-check torch\n",
    "# %pip install transformers sentence-transformers\n",
    "# %pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b1627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "import re\n",
    "import itertools\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "751e7c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    {\n",
    "        \"question\": \"What is a variable in programming?\",\n",
    "        \"answer\": \"A variable is a named memory location used to store data that can be read or modified during program execution.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the difference between a list and an array?\",\n",
    "        \"answer\": \"A list can grow or shrink dynamically, while an array usually has a fixed size and often stores elements of the same data type.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is a for loop used for?\",\n",
    "        \"answer\": \"A for loop is used to repeat a block of code a specific number of times or to iterate over a collection of elements.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is a function?\",\n",
    "        \"answer\": \"A function is a reusable block of code designed to perform a specific task, which can accept parameters and optionally return a result.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is an API?\",\n",
    "        \"answer\": \"An API (Application Programming Interface) defines rules and methods that allow different software applications to communicate with each other.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What does it mean to debug a program?\",\n",
    "        \"answer\": \"Debugging is the process of identifying, analyzing, and fixing errors or unexpected behavior in a program.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is an exception?\",\n",
    "        \"answer\": \"An exception is an error or unexpected event that occurs during program execution and can disrupt the normal flow of the program.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Difference between == and === in JavaScript?\",\n",
    "        \"answer\": \"== compares values after performing type conversion, while === compares both value and type without any conversion.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is an algorithm?\",\n",
    "        \"answer\": \"An algorithm is a well-defined, step-by-step procedure used to solve a problem or perform a computation.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What does open source mean?\",\n",
    "        \"answer\": \"Open source software has source code that is publicly available and can be studied, modified, and distributed by anyone.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is an object in OOP?\",\n",
    "        \"answer\": \"An object is an instance of a class that contains data (attributes) and behavior (methods) related to that data.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is Git used for?\",\n",
    "        \"answer\": \"Git is a version control system used to track changes in source code and collaborate efficiently with other developers.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is an infinite loop?\",\n",
    "        \"answer\": \"An infinite loop is a loop that runs indefinitely because its stopping condition is never met or never changes.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is an SQL SELECT query?\",\n",
    "        \"answer\": \"A SELECT query is used to retrieve specific data from one or more tables in a database.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do frontend and backend mean?\",\n",
    "        \"answer\": \"Frontend refers to the user-facing part of an application, while backend handles server-side logic, databases, and application processing.\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84451936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "LLM_MODEL device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "# MODEL_NAME = \"unsloth/Phi-3-mini-4k-instruct-bnb-4bit\"\n",
    "MODEL_NAME = \"Gensyn/Qwen2.5-1.5B-Instruct\"\n",
    "EMBEDDING_MODEL = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "LLM_MODEL = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "LLM_MODEL.to(DEVICE)\n",
    "_ = LLM_MODEL.eval()\n",
    "\n",
    "# print LLM_MODEL device\n",
    "print(f\"LLM_MODEL device: {next(LLM_MODEL.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ab1132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of shots: 0\n",
      "Prompt:\n",
      "QUESTION:\n",
      "What is an infinite loop?\n",
      "ANSWER:\n",
      "\n",
      "Prompt:\n",
      "QUESTION:\n",
      "What is a for loop used for?\n",
      "ANSWER:\n",
      "\n",
      "Number of shots: 2\n",
      "Prompt:\n",
      "QUESTION:\n",
      "What is a for loop used for?\n",
      "ANSWER:\n",
      "A for loop is used to repeat a block of code a specific number of times or to iterate over a collection of elements.\n",
      "\n",
      "QUESTION:\n",
      "What is an SQL SELECT query?\n",
      "ANSWER:\n",
      "A SELECT query is used to retrieve specific data from one or more tables in a database.\n",
      "\n",
      "QUESTION:\n",
      "What is an infinite loop?\n",
      "ANSWER:\n",
      "\n",
      "Prompt:\n",
      "QUESTION:\n",
      "What does open source mean?\n",
      "ANSWER:\n",
      "Open source software has source code that is publicly available and can be studied, modified, and distributed by anyone.\n",
      "\n",
      "QUESTION:\n",
      "What is an API?\n",
      "ANSWER:\n",
      "An API (Application Programming Interface) defines rules and methods that allow different software applications to communicate with each other.\n",
      "\n",
      "QUESTION:\n",
      "What is a for loop used for?\n",
      "ANSWER:\n",
      "\n",
      "Number of shots: 4\n",
      "Prompt:\n",
      "QUESTION:\n",
      "What is a for loop used for?\n",
      "ANSWER:\n",
      "A for loop is used to repeat a block of code a specific number of times or to iterate over a collection of elements.\n",
      "\n",
      "QUESTION:\n",
      "What is an SQL SELECT query?\n",
      "ANSWER:\n",
      "A SELECT query is used to retrieve specific data from one or more tables in a database.\n",
      "\n",
      "QUESTION:\n",
      "What is the difference between a list and an array?\n",
      "ANSWER:\n",
      "A list can grow or shrink dynamically, while an array usually has a fixed size and often stores elements of the same data type.\n",
      "\n",
      "QUESTION:\n",
      "What is an object in OOP?\n",
      "ANSWER:\n",
      "An object is an instance of a class that contains data (attributes) and behavior (methods) related to that data.\n",
      "\n",
      "QUESTION:\n",
      "What is an infinite loop?\n",
      "ANSWER:\n",
      "\n",
      "Prompt:\n",
      "QUESTION:\n",
      "What does open source mean?\n",
      "ANSWER:\n",
      "Open source software has source code that is publicly available and can be studied, modified, and distributed by anyone.\n",
      "\n",
      "QUESTION:\n",
      "What is an API?\n",
      "ANSWER:\n",
      "An API (Application Programming Interface) defines rules and methods that allow different software applications to communicate with each other.\n",
      "\n",
      "QUESTION:\n",
      "What is an object in OOP?\n",
      "ANSWER:\n",
      "An object is an instance of a class that contains data (attributes) and behavior (methods) related to that data.\n",
      "\n",
      "QUESTION:\n",
      "What do frontend and backend mean?\n",
      "ANSWER:\n",
      "Frontend refers to the user-facing part of an application, while backend handles server-side logic, databases, and application processing.\n",
      "\n",
      "QUESTION:\n",
      "What is a for loop used for?\n",
      "ANSWER:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Data:\n",
    "    \"\"\"\n",
    "    Simple container for a question/answer pair.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    question : str\n",
    "        The question text.\n",
    "    answer : str\n",
    "        The answer text.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dict\n",
    "        A mapping with keys \"question\" and \"answer\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data: dict):\n",
    "        self.question = data[\"question\"]\n",
    "        self.answer = data[\"answer\"]\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Return a string representation of the Data object.\"\"\"\n",
    "        return f\"Data(question={self.question}, answer={self.answer})\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\"\n",
    "        Check equality between two Data objects.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        other : Data\n",
    "            Another Data object to compare with.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            True if both question and answer match, NotImplemented if other is not a Data.\n",
    "        \"\"\"\n",
    "        if not isinstance(other, Data):\n",
    "            return NotImplemented\n",
    "        return self.question == other.question and self.answer == other.answer\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    \"\"\"\n",
    "    Collection of Data objects with convenient accessors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : list[dict]\n",
    "        Iterable of dictionaries, each containing \"question\" and \"answer\".\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    data : list[Data]\n",
    "        List of Data objects created from input dictionaries.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data: list):\n",
    "        self.data = [Data(entry) for entry in data]\n",
    "\n",
    "    def get_random_entry(self):\n",
    "        \"\"\"Return a single random Data object from the dataset.\"\"\"\n",
    "        return random.choice(self.data)\n",
    "\n",
    "    def get_all_entries(self):\n",
    "        \"\"\"Return the list of all Data objects.\"\"\"\n",
    "        return self.data\n",
    "\n",
    "    def generate_random_entries(\n",
    "        self, count: int = 1, forbiden_entry: list[Data] = []\n",
    "    ) -> list[Data]:\n",
    "        \"\"\"\n",
    "        Generate a list of unique random Data entries, excluding forbidden ones.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        count : int, optional (default=1)\n",
    "            Number of random entries to generate.\n",
    "        forbiden_entry : list[Data], optional (default=[])\n",
    "            List of Data entries to exclude from selection.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[Data]\n",
    "            A list of randomly selected Data objects.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        AssertionError\n",
    "            If count is not between 0 and dataset size minus one.\n",
    "        \"\"\"\n",
    "        assert (\n",
    "            0 <= count <= len(self.data) - 1\n",
    "        ), \"n must be between 0 and the size of the dataset minus one.\"\n",
    "        other_entries = random.sample(\n",
    "            list(itertools.filterfalse(lambda e: e in forbiden_entry, self.data)),\n",
    "            count,\n",
    "        )\n",
    "        return other_entries\n",
    "\n",
    "    def add_other_entries(\n",
    "        self,\n",
    "        forbiden_entry: list[Data],\n",
    "        other_entries: list[Data],\n",
    "        number_of_shots: int,\n",
    "    ) -> list[Data]:\n",
    "        \"\"\"\n",
    "        Add additional random entries to an existing list, avoiding duplicates.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        forbiden_entry : list[Data]\n",
    "            List of Data entries to exclude from selection.\n",
    "        other_entries : list[Data]\n",
    "            Existing list of entries to extend.\n",
    "        number_of_shots : int\n",
    "            Number of additional entries to add.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[Data]\n",
    "            Combined list of other_entries plus the additional random entries.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        AssertionError\n",
    "            If number_of_shots is not between 0 and dataset size minus one.\n",
    "        \"\"\"\n",
    "        assert (\n",
    "            0 <= number_of_shots <= len(self.data) - 1\n",
    "        ), \"n must be between 0 and the size of the dataset minus one.\"\n",
    "        additional_entries = random.sample(\n",
    "            list(\n",
    "                itertools.filterfalse(\n",
    "                    lambda e: e in forbiden_entry or e in other_entries, self.data\n",
    "                )\n",
    "            ),\n",
    "            number_of_shots,\n",
    "        )\n",
    "        return other_entries + additional_entries\n",
    "\n",
    "    def build_prompt(self, main_entry: Data, other_entries: list[Data]) -> str:\n",
    "        \"\"\"\n",
    "        Build a formatted prompt string from example entries and a main question.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        main_entry : Data\n",
    "            The main question/answer pair whose question will be asked.\n",
    "        other_entries : list[Data]\n",
    "            List of example question/answer pairs to include as few-shot examples.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Formatted prompt with examples followed by the main question.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        AssertionError\n",
    "            If main_entry is not part of the dataset.\n",
    "        \"\"\"\n",
    "        assert main_entry in self.data, \"main_entry must be part of the dataset\"\n",
    "\n",
    "        return (\n",
    "            \"\".join(\n",
    "                f\"QUESTION:\\n{e.question}\\nANSWER:\\n{e.answer}\\n\\n\"\n",
    "                for e in other_entries\n",
    "            )\n",
    "            + f\"QUESTION:\\n{main_entry.question}\\nANSWER:\\n\"\n",
    "        )\n",
    "\n",
    "    def generate_prompt(self, number_of_shots: int = 0) -> tuple[str, Data]:\n",
    "        \"\"\"\n",
    "        Generate a few-shot prompt for the language model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        number_of_shots : int, optional (default=0)\n",
    "            Number of example question/answer pairs to include before the main question.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple[str, Data]\n",
    "            A tuple containing:\n",
    "            - The formatted prompt string with examples and the main question.\n",
    "            - The main Data entry whose answer should be generated.\n",
    "        \"\"\"\n",
    "        main_entry = self.get_random_entry()\n",
    "        other_entries = self.generate_random_entries(\n",
    "            count=number_of_shots, forbiden_entry=[main_entry]\n",
    "        )\n",
    "        prompt = self.build_prompt(main_entry, other_entries)\n",
    "        return prompt, main_entry\n",
    "\n",
    "    def generate_multiple_prompts(\n",
    "        self, count=1, number_of_shots=[0]\n",
    "    ) -> dict[int, list[tuple[str, Data]]]:\n",
    "        \"\"\"\n",
    "        Generate multiple few-shot prompts for different shot counts.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        count : int, optional (default=1)\n",
    "            Number of main entries to generate prompts for.\n",
    "        number_of_shots : list[int], optional (default=[0])\n",
    "            List of shot counts to generate prompts for each main entry.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict[int, list[tuple[str, Data]]]\n",
    "            A dictionary mapping each shot count to a list of tuples, where each tuple contains:\n",
    "            - The formatted prompt string with examples and the main question.\n",
    "            - The main Data entry whose answer should be generated.\n",
    "        \"\"\"\n",
    "        number_of_shots = sorted(number_of_shots)\n",
    "        prompts = {}\n",
    "        for shots in number_of_shots:\n",
    "            prompts[shots] = []\n",
    "        main_entries = self.generate_random_entries(count=count)\n",
    "        for main_entry in main_entries:\n",
    "            current_other_entries = []\n",
    "            for shots in number_of_shots:\n",
    "                if shots > 0:\n",
    "                    current_other_entries = self.add_other_entries(\n",
    "                        forbiden_entry=[main_entry],\n",
    "                        other_entries=current_other_entries,\n",
    "                        number_of_shots=shots - len(current_other_entries),\n",
    "                    )\n",
    "                prompt = self.build_prompt(main_entry, current_other_entries)\n",
    "                prompts[shots].append((prompt, main_entry))\n",
    "        return prompts\n",
    "\n",
    "\n",
    "class Evaluator:\n",
    "    \"\"\"\n",
    "    Evaluator for assessing model-generated answers.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    embedding_model : SentenceTransformer\n",
    "        The embedding model used for computing semantic similarity.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    model : SentenceTransformer\n",
    "        The embedding model instance.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_model):\n",
    "        self.model = embedding_model\n",
    "\n",
    "    def evaluate(self, generated_answer: str, reference_answer: str) -> float:\n",
    "        \"\"\"\n",
    "        Compute the score for a generated answer against a reference answer. using only embedding similarity.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        generated_answer : str\n",
    "            The model-generated answer.\n",
    "        reference_answer : str\n",
    "            The reference/expected answer.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The computed evaluation score between 0.0 and 1.0.\n",
    "        \"\"\"\n",
    "        # Embedding similarity\n",
    "        emb_gen = self.model.encode(generated_answer, convert_to_tensor=True)\n",
    "        emb_ref = self.model.encode(reference_answer, convert_to_tensor=True)\n",
    "        embedding_score = util.cos_sim(emb_gen, emb_ref).item()\n",
    "\n",
    "        return float(embedding_score)\n",
    "\n",
    "\n",
    "evaluator = Evaluator(EMBEDDING_MODEL)\n",
    "ds = Dataset(data=dataset)\n",
    "res = ds.generate_multiple_prompts(count=2, number_of_shots=[0, 2, 4])\n",
    "for k, v in res.items():\n",
    "    print(f\"Number of shots: {k}\")\n",
    "    for prompt, main_entry in v:\n",
    "        print(\"Prompt:\")\n",
    "        print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97ea2618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "QUESTION:\n",
      "What do frontend and backend mean?\n",
      "ANSWER:\n",
      "Frontend refers to the user-facing part of an application, while backend handles server-side logic, databases, and application processing.\n",
      "\n",
      "QUESTION:\n",
      "What is a variable in programming?\n",
      "ANSWER:\n",
      "A variable is a named memory location used to store data that can be read or modified during program execution.\n",
      "\n",
      "QUESTION:\n",
      "What is an SQL SELECT query?\n",
      "ANSWER:\n",
      "A SELECT query is used to retrieve specific data from one or more tables in a database.\n",
      "\n",
      "QUESTION:\n",
      "What is Git used for?\n",
      "ANSWER:\n",
      "\n",
      "Generated: Git is primarily used for version control in software development projects. It allows developers to track changes made to code over time, collaborate with others on the same project, and revert to previous versions if necessary. Git also supports branching and merging, which allow teams to work on different features simultaneously without interfering with each other's progress.\n",
      "Expected: Git is a version control system used to track changes in source code and collaborate efficiently with other developers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9147955775260925"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LLM:\n",
    "    \"\"\"\n",
    "    Wrapper for tokenizer and model to generate chat responses.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tokenizer : AutoTokenizer\n",
    "        The tokenizer to use for encoding/decoding.\n",
    "    model : AutoModelForCausalLM\n",
    "        The language model for generation.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    tokenizer : AutoTokenizer\n",
    "        The tokenizer instance.\n",
    "    model : AutoModelForCausalLM\n",
    "        The language model instance.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tokenizer, model):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "\n",
    "    def invoke(\n",
    "        self,\n",
    "        messages,\n",
    "        temperature=0.0,\n",
    "        top_k=50,\n",
    "        top_p=0.9,\n",
    "        max_new_tokens=128,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Generate a response from the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        messages : str or list\n",
    "            The user message/prompt to send to the model. Can be a string\n",
    "            (which will be wrapped as a user message) or a list of message dicts.\n",
    "        temperature : float, optional (default=0.0)\n",
    "            Controls randomness in generation. Higher values (e.g., 1.5) make\n",
    "            output more random, lower values (e.g., 0.2) make it more deterministic.\n",
    "            When set to 0.0, greedy decoding is used (do_sample=False).\n",
    "        top_k : int, optional (default=50)\n",
    "            Number of highest probability tokens to keep for top-k filtering.\n",
    "        top_p : float, optional (default=0.9)\n",
    "            Nucleus sampling: keeps the smallest set of tokens whose cumulative\n",
    "            probability exceeds top_p.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The generated response with thinking tags removed.\n",
    "        \"\"\"\n",
    "        # Convert string to chat format if needed\n",
    "        if isinstance(messages, str):\n",
    "            messages = [{\"role\": \"user\", \"content\": messages}]\n",
    "\n",
    "        # Apply chat template and tokenize\n",
    "        inputs = self.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            return_tensors=\"pt\",\n",
    "            add_generation_prompt=True,\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        do_sample = True\n",
    "        if temperature == 0.0:\n",
    "            do_sample = False\n",
    "\n",
    "        # Build generation kwargs\n",
    "        gen_kwargs = {\n",
    "            \"do_sample\": do_sample,\n",
    "            \"pad_token_id\": self.tokenizer.eos_token_id,\n",
    "            \"max_new_tokens\": max_new_tokens,\n",
    "        }\n",
    "        if do_sample:\n",
    "            gen_kwargs[\"temperature\"] = temperature\n",
    "            gen_kwargs[\"top_k\"] = top_k\n",
    "            gen_kwargs[\"top_p\"] = top_p\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(inputs, **gen_kwargs)\n",
    "        decoded = self.tokenizer.decode(\n",
    "            outputs[0][inputs.shape[-1] :],\n",
    "            skip_special_tokens=True,\n",
    "        )\n",
    "        # remove <think>...</think> tags\n",
    "        cleaned = re.sub(r\"<think>.*?</think>\", \"\", decoded, flags=re.DOTALL).strip()\n",
    "        return cleaned\n",
    "\n",
    "\n",
    "llm = LLM(TOKENIZER, LLM_MODEL)\n",
    "prompt, main_entry = ds.generate_prompt(number_of_shots=3)\n",
    "print(f\"Prompt:\\n{prompt}\")\n",
    "response = llm.invoke(prompt)\n",
    "print(\"Generated:\", response)\n",
    "print(\"Expected:\", main_entry.answer)\n",
    "evaluator.evaluate(response, main_entry.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f559f030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing parameter combinations:   0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing parameter combinations: 100%|██████████| 54/54 [12:09<00:00, 13.51s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_75679_row0_col4 {\n",
       "  background-color: #006837;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_75679_row1_col4 {\n",
       "  background-color: #8ccd67;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row2_col4 {\n",
       "  background-color: #98d368;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row3_col4, #T_75679_row4_col4 {\n",
       "  background-color: #9dd569;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row5_col4 {\n",
       "  background-color: #a2d76a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row6_col4 {\n",
       "  background-color: #b5df74;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row7_col4 {\n",
       "  background-color: #bfe47a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row8_col4 {\n",
       "  background-color: #cdea83;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row9_col4 {\n",
       "  background-color: #d5ed88;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row10_col4 {\n",
       "  background-color: #e6f59d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row11_col4 {\n",
       "  background-color: #f1f9ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row12_col4 {\n",
       "  background-color: #f4fab0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row13_col4 {\n",
       "  background-color: #f5fbb2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row14_col4 {\n",
       "  background-color: #f7fcb4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row15_col4, #T_75679_row16_col4 {\n",
       "  background-color: #fafdb8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row17_col4, #T_75679_row18_col4 {\n",
       "  background-color: #feffbe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row19_col4 {\n",
       "  background-color: #fffdbc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row20_col4 {\n",
       "  background-color: #fffab6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row21_col4 {\n",
       "  background-color: #fff7b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row22_col4 {\n",
       "  background-color: #fff5ae;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row23_col4 {\n",
       "  background-color: #fff1a8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row24_col4 {\n",
       "  background-color: #feeda1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row25_col4 {\n",
       "  background-color: #feec9f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row26_col4 {\n",
       "  background-color: #fee18d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row27_col4 {\n",
       "  background-color: #fed683;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row28_col4 {\n",
       "  background-color: #feca79;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row29_col4 {\n",
       "  background-color: #fdc372;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row30_col4 {\n",
       "  background-color: #fdb365;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row31_col4 {\n",
       "  background-color: #fdb163;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row32_col4 {\n",
       "  background-color: #fcaa5f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row33_col4 {\n",
       "  background-color: #fca85e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row34_col4 {\n",
       "  background-color: #fba05b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_75679_row35_col4 {\n",
       "  background-color: #f88c51;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_75679_row36_col4 {\n",
       "  background-color: #f47044;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_75679_row37_col4 {\n",
       "  background-color: #be1827;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_75679_row38_col4 {\n",
       "  background-color: #a50026;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_75679\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_75679_level0_col0\" class=\"col_heading level0 col0\" >number_of_shots</th>\n",
       "      <th id=\"T_75679_level0_col1\" class=\"col_heading level0 col1\" >temperature</th>\n",
       "      <th id=\"T_75679_level0_col2\" class=\"col_heading level0 col2\" >top_k</th>\n",
       "      <th id=\"T_75679_level0_col3\" class=\"col_heading level0 col3\" >top_p</th>\n",
       "      <th id=\"T_75679_level0_col4\" class=\"col_heading level0 col4\" >avg_score</th>\n",
       "      <th id=\"T_75679_level0_col5\" class=\"col_heading level0 col5\" >min_score</th>\n",
       "      <th id=\"T_75679_level0_col6\" class=\"col_heading level0 col6\" >max_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row0\" class=\"row_heading level0 row0\" >34</th>\n",
       "      <td id=\"T_75679_row0_col0\" class=\"data row0 col0\" >4</td>\n",
       "      <td id=\"T_75679_row0_col1\" class=\"data row0 col1\" >1.000000</td>\n",
       "      <td id=\"T_75679_row0_col2\" class=\"data row0 col2\" >10</td>\n",
       "      <td id=\"T_75679_row0_col3\" class=\"data row0 col3\" >0.950000</td>\n",
       "      <td id=\"T_75679_row0_col4\" class=\"data row0 col4\" >0.884110</td>\n",
       "      <td id=\"T_75679_row0_col5\" class=\"data row0 col5\" >0.776679</td>\n",
       "      <td id=\"T_75679_row0_col6\" class=\"data row0 col6\" >0.943708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row1\" class=\"row_heading level0 row1\" >30</th>\n",
       "      <td id=\"T_75679_row1_col0\" class=\"data row1 col0\" >4</td>\n",
       "      <td id=\"T_75679_row1_col1\" class=\"data row1 col1\" >0.500000</td>\n",
       "      <td id=\"T_75679_row1_col2\" class=\"data row1 col2\" >50</td>\n",
       "      <td id=\"T_75679_row1_col3\" class=\"data row1 col3\" >0.950000</td>\n",
       "      <td id=\"T_75679_row1_col4\" class=\"data row1 col4\" >0.863073</td>\n",
       "      <td id=\"T_75679_row1_col5\" class=\"data row1 col5\" >0.787918</td>\n",
       "      <td id=\"T_75679_row1_col6\" class=\"data row1 col6\" >0.923309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row2\" class=\"row_heading level0 row2\" >35</th>\n",
       "      <td id=\"T_75679_row2_col0\" class=\"data row2 col0\" >4</td>\n",
       "      <td id=\"T_75679_row2_col1\" class=\"data row2 col1\" >1.000000</td>\n",
       "      <td id=\"T_75679_row2_col2\" class=\"data row2 col2\" >50</td>\n",
       "      <td id=\"T_75679_row2_col3\" class=\"data row2 col3\" >0.700000</td>\n",
       "      <td id=\"T_75679_row2_col4\" class=\"data row2 col4\" >0.861314</td>\n",
       "      <td id=\"T_75679_row2_col5\" class=\"data row2 col5\" >0.800364</td>\n",
       "      <td id=\"T_75679_row2_col6\" class=\"data row2 col6\" >0.960746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row3\" class=\"row_heading level0 row3\" >19</th>\n",
       "      <td id=\"T_75679_row3_col0\" class=\"data row3 col0\" >2</td>\n",
       "      <td id=\"T_75679_row3_col1\" class=\"data row3 col1\" >0.500000</td>\n",
       "      <td id=\"T_75679_row3_col2\" class=\"data row3 col2\" >100</td>\n",
       "      <td id=\"T_75679_row3_col3\" class=\"data row3 col3\" >0.950000</td>\n",
       "      <td id=\"T_75679_row3_col4\" class=\"data row3 col4\" >0.860746</td>\n",
       "      <td id=\"T_75679_row3_col5\" class=\"data row3 col5\" >0.782637</td>\n",
       "      <td id=\"T_75679_row3_col6\" class=\"data row3 col6\" >0.956435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row4\" class=\"row_heading level0 row4\" >27</th>\n",
       "      <td id=\"T_75679_row4_col0\" class=\"data row4 col0\" >4</td>\n",
       "      <td id=\"T_75679_row4_col1\" class=\"data row4 col1\" >0.500000</td>\n",
       "      <td id=\"T_75679_row4_col2\" class=\"data row4 col2\" >10</td>\n",
       "      <td id=\"T_75679_row4_col3\" class=\"data row4 col3\" >0.700000</td>\n",
       "      <td id=\"T_75679_row4_col4\" class=\"data row4 col4\" >0.860742</td>\n",
       "      <td id=\"T_75679_row4_col5\" class=\"data row4 col5\" >0.753754</td>\n",
       "      <td id=\"T_75679_row4_col6\" class=\"data row4 col6\" >0.919437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row5\" class=\"row_heading level0 row5\" >28</th>\n",
       "      <td id=\"T_75679_row5_col0\" class=\"data row5 col0\" >4</td>\n",
       "      <td id=\"T_75679_row5_col1\" class=\"data row5 col1\" >0.500000</td>\n",
       "      <td id=\"T_75679_row5_col2\" class=\"data row5 col2\" >10</td>\n",
       "      <td id=\"T_75679_row5_col3\" class=\"data row5 col3\" >0.950000</td>\n",
       "      <td id=\"T_75679_row5_col4\" class=\"data row5 col4\" >0.860099</td>\n",
       "      <td id=\"T_75679_row5_col5\" class=\"data row5 col5\" >0.751727</td>\n",
       "      <td id=\"T_75679_row5_col6\" class=\"data row5 col6\" >0.910308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row6\" class=\"row_heading level0 row6\" >29</th>\n",
       "      <td id=\"T_75679_row6_col0\" class=\"data row6 col0\" >4</td>\n",
       "      <td id=\"T_75679_row6_col1\" class=\"data row6 col1\" >0.500000</td>\n",
       "      <td id=\"T_75679_row6_col2\" class=\"data row6 col2\" >50</td>\n",
       "      <td id=\"T_75679_row6_col3\" class=\"data row6 col3\" >0.700000</td>\n",
       "      <td id=\"T_75679_row6_col4\" class=\"data row6 col4\" >0.857302</td>\n",
       "      <td id=\"T_75679_row6_col5\" class=\"data row6 col5\" >0.718529</td>\n",
       "      <td id=\"T_75679_row6_col6\" class=\"data row6 col6\" >0.938707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row7\" class=\"row_heading level0 row7\" >25</th>\n",
       "      <td id=\"T_75679_row7_col0\" class=\"data row7 col0\" >2</td>\n",
       "      <td id=\"T_75679_row7_col1\" class=\"data row7 col1\" >1.000000</td>\n",
       "      <td id=\"T_75679_row7_col2\" class=\"data row7 col2\" >100</td>\n",
       "      <td id=\"T_75679_row7_col3\" class=\"data row7 col3\" >0.950000</td>\n",
       "      <td id=\"T_75679_row7_col4\" class=\"data row7 col4\" >0.855636</td>\n",
       "      <td id=\"T_75679_row7_col5\" class=\"data row7 col5\" >0.748596</td>\n",
       "      <td id=\"T_75679_row7_col6\" class=\"data row7 col6\" >0.946788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row8\" class=\"row_heading level0 row8\" >26</th>\n",
       "      <td id=\"T_75679_row8_col0\" class=\"data row8 col0\" >4</td>\n",
       "      <td id=\"T_75679_row8_col1\" class=\"data row8 col1\" >0.000000</td>\n",
       "      <td id=\"T_75679_row8_col2\" class=\"data row8 col2\" >10</td>\n",
       "      <td id=\"T_75679_row8_col3\" class=\"data row8 col3\" >0.700000</td>\n",
       "      <td id=\"T_75679_row8_col4\" class=\"data row8 col4\" >0.853578</td>\n",
       "      <td id=\"T_75679_row8_col5\" class=\"data row8 col5\" >0.733064</td>\n",
       "      <td id=\"T_75679_row8_col6\" class=\"data row8 col6\" >0.955262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row9\" class=\"row_heading level0 row9\" >23</th>\n",
       "      <td id=\"T_75679_row9_col0\" class=\"data row9 col0\" >2</td>\n",
       "      <td id=\"T_75679_row9_col1\" class=\"data row9 col1\" >1.000000</td>\n",
       "      <td id=\"T_75679_row9_col2\" class=\"data row9 col2\" >50</td>\n",
       "      <td id=\"T_75679_row9_col3\" class=\"data row9 col3\" >0.950000</td>\n",
       "      <td id=\"T_75679_row9_col4\" class=\"data row9 col4\" >0.852135</td>\n",
       "      <td id=\"T_75679_row9_col5\" class=\"data row9 col5\" >0.732997</td>\n",
       "      <td id=\"T_75679_row9_col6\" class=\"data row9 col6\" >0.915890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row10\" class=\"row_heading level0 row10\" >20</th>\n",
       "      <td id=\"T_75679_row10_col0\" class=\"data row10 col0\" >2</td>\n",
       "      <td id=\"T_75679_row10_col1\" class=\"data row10 col1\" >1.000000</td>\n",
       "      <td id=\"T_75679_row10_col2\" class=\"data row10 col2\" >10</td>\n",
       "      <td id=\"T_75679_row10_col3\" class=\"data row10 col3\" >0.700000</td>\n",
       "      <td id=\"T_75679_row10_col4\" class=\"data row10 col4\" >0.848831</td>\n",
       "      <td id=\"T_75679_row10_col5\" class=\"data row10 col5\" >0.758030</td>\n",
       "      <td id=\"T_75679_row10_col6\" class=\"data row10 col6\" >0.910295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row11\" class=\"row_heading level0 row11\" >4</th>\n",
       "      <td id=\"T_75679_row11_col0\" class=\"data row11 col0\" >0</td>\n",
       "      <td id=\"T_75679_row11_col1\" class=\"data row11 col1\" >0.500000</td>\n",
       "      <td id=\"T_75679_row11_col2\" class=\"data row11 col2\" >50</td>\n",
       "      <td id=\"T_75679_row11_col3\" class=\"data row11 col3\" >0.950000</td>\n",
       "      <td id=\"T_75679_row11_col4\" class=\"data row11 col4\" >0.846519</td>\n",
       "      <td id=\"T_75679_row11_col5\" class=\"data row11 col5\" >0.801353</td>\n",
       "      <td id=\"T_75679_row11_col6\" class=\"data row11 col6\" >0.888501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row12\" class=\"row_heading level0 row12\" >7</th>\n",
       "      <td id=\"T_75679_row12_col0\" class=\"data row12 col0\" >0</td>\n",
       "      <td id=\"T_75679_row12_col1\" class=\"data row12 col1\" >1.000000</td>\n",
       "      <td id=\"T_75679_row12_col2\" class=\"data row12 col2\" >10</td>\n",
       "      <td id=\"T_75679_row12_col3\" class=\"data row12 col3\" >0.700000</td>\n",
       "      <td id=\"T_75679_row12_col4\" class=\"data row12 col4\" >0.845911</td>\n",
       "      <td id=\"T_75679_row12_col5\" class=\"data row12 col5\" >0.792409</td>\n",
       "      <td id=\"T_75679_row12_col6\" class=\"data row12 col6\" >0.878002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_75679_row13_col0\" class=\"data row13 col0\" >2</td>\n",
       "      <td id=\"T_75679_row13_col1\" class=\"data row13 col1\" >0.000000</td>\n",
       "      <td id=\"T_75679_row13_col2\" class=\"data row13 col2\" >10</td>\n",
       "      <td id=\"T_75679_row13_col3\" class=\"data row13 col3\" >0.700000</td>\n",
       "      <td id=\"T_75679_row13_col4\" class=\"data row13 col4\" >0.845621</td>\n",
       "      <td id=\"T_75679_row13_col5\" class=\"data row13 col5\" >0.726980</td>\n",
       "      <td id=\"T_75679_row13_col6\" class=\"data row13 col6\" >0.930786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row14\" class=\"row_heading level0 row14\" >33</th>\n",
       "      <td id=\"T_75679_row14_col0\" class=\"data row14 col0\" >4</td>\n",
       "      <td id=\"T_75679_row14_col1\" class=\"data row14 col1\" >1.000000</td>\n",
       "      <td id=\"T_75679_row14_col2\" class=\"data row14 col2\" >10</td>\n",
       "      <td id=\"T_75679_row14_col3\" class=\"data row14 col3\" >0.700000</td>\n",
       "      <td id=\"T_75679_row14_col4\" class=\"data row14 col4\" >0.845291</td>\n",
       "      <td id=\"T_75679_row14_col5\" class=\"data row14 col5\" >0.704510</td>\n",
       "      <td id=\"T_75679_row14_col6\" class=\"data row14 col6\" >0.939763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row15\" class=\"row_heading level0 row15\" >3</th>\n",
       "      <td id=\"T_75679_row15_col0\" class=\"data row15 col0\" >0</td>\n",
       "      <td id=\"T_75679_row15_col1\" class=\"data row15 col1\" >0.500000</td>\n",
       "      <td id=\"T_75679_row15_col2\" class=\"data row15 col2\" >50</td>\n",
       "      <td id=\"T_75679_row15_col3\" class=\"data row15 col3\" >0.700000</td>\n",
       "      <td id=\"T_75679_row15_col4\" class=\"data row15 col4\" >0.844759</td>\n",
       "      <td id=\"T_75679_row15_col5\" class=\"data row15 col5\" >0.798998</td>\n",
       "      <td id=\"T_75679_row15_col6\" class=\"data row15 col6\" >0.884837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row16\" class=\"row_heading level0 row16\" >21</th>\n",
       "      <td id=\"T_75679_row16_col0\" class=\"data row16 col0\" >2</td>\n",
       "      <td id=\"T_75679_row16_col1\" class=\"data row16 col1\" >1.000000</td>\n",
       "      <td id=\"T_75679_row16_col2\" class=\"data row16 col2\" >10</td>\n",
       "      <td id=\"T_75679_row16_col3\" class=\"data row16 col3\" >0.950000</td>\n",
       "      <td id=\"T_75679_row16_col4\" class=\"data row16 col4\" >0.844705</td>\n",
       "      <td id=\"T_75679_row16_col5\" class=\"data row16 col5\" >0.735473</td>\n",
       "      <td id=\"T_75679_row16_col6\" class=\"data row16 col6\" >0.901263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row17\" class=\"row_heading level0 row17\" >22</th>\n",
       "      <td id=\"T_75679_row17_col0\" class=\"data row17 col0\" >2</td>\n",
       "      <td id=\"T_75679_row17_col1\" class=\"data row17 col1\" >1.000000</td>\n",
       "      <td id=\"T_75679_row17_col2\" class=\"data row17 col2\" >50</td>\n",
       "      <td id=\"T_75679_row17_col3\" class=\"data row17 col3\" >0.700000</td>\n",
       "      <td id=\"T_75679_row17_col4\" class=\"data row17 col4\" >0.843828</td>\n",
       "      <td id=\"T_75679_row17_col5\" class=\"data row17 col5\" >0.744383</td>\n",
       "      <td id=\"T_75679_row17_col6\" class=\"data row17 col6\" >0.904617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row18\" class=\"row_heading level0 row18\" >2</th>\n",
       "      <td id=\"T_75679_row18_col0\" class=\"data row18 col0\" >0</td>\n",
       "      <td id=\"T_75679_row18_col1\" class=\"data row18 col1\" >0.500000</td>\n",
       "      <td id=\"T_75679_row18_col2\" class=\"data row18 col2\" >10</td>\n",
       "      <td id=\"T_75679_row18_col3\" class=\"data row18 col3\" >0.950000</td>\n",
       "      <td id=\"T_75679_row18_col4\" class=\"data row18 col4\" >0.843723</td>\n",
       "      <td id=\"T_75679_row18_col5\" class=\"data row18 col5\" >0.745135</td>\n",
       "      <td id=\"T_75679_row18_col6\" class=\"data row18 col6\" >0.916284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row19\" class=\"row_heading level0 row19\" >16</th>\n",
       "      <td id=\"T_75679_row19_col0\" class=\"data row19 col0\" >2</td>\n",
       "      <td id=\"T_75679_row19_col1\" class=\"data row19 col1\" >0.500000</td>\n",
       "      <td id=\"T_75679_row19_col2\" class=\"data row19 col2\" >50</td>\n",
       "      <td id=\"T_75679_row19_col3\" class=\"data row19 col3\" >0.700000</td>\n",
       "      <td id=\"T_75679_row19_col4\" class=\"data row19 col4\" >0.843046</td>\n",
       "      <td id=\"T_75679_row19_col5\" class=\"data row19 col5\" >0.738999</td>\n",
       "      <td id=\"T_75679_row19_col6\" class=\"data row19 col6\" >0.919557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row20\" class=\"row_heading level0 row20\" >32</th>\n",
       "      <td id=\"T_75679_row20_col0\" class=\"data row20 col0\" >4</td>\n",
       "      <td id=\"T_75679_row20_col1\" class=\"data row20 col1\" >0.500000</td>\n",
       "      <td id=\"T_75679_row20_col2\" class=\"data row20 col2\" >100</td>\n",
       "      <td id=\"T_75679_row20_col3\" class=\"data row20 col3\" >0.950000</td>\n",
       "      <td id=\"T_75679_row20_col4\" class=\"data row20 col4\" >0.842290</td>\n",
       "      <td id=\"T_75679_row20_col5\" class=\"data row20 col5\" >0.729120</td>\n",
       "      <td id=\"T_75679_row20_col6\" class=\"data row20 col6\" >0.953099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row21\" class=\"row_heading level0 row21\" >5</th>\n",
       "      <td id=\"T_75679_row21_col0\" class=\"data row21 col0\" >0</td>\n",
       "      <td id=\"T_75679_row21_col1\" class=\"data row21 col1\" >0.500000</td>\n",
       "      <td id=\"T_75679_row21_col2\" class=\"data row21 col2\" >100</td>\n",
       "      <td id=\"T_75679_row21_col3\" class=\"data row21 col3\" >0.700000</td>\n",
       "      <td id=\"T_75679_row21_col4\" class=\"data row21 col4\" >0.841603</td>\n",
       "      <td id=\"T_75679_row21_col5\" class=\"data row21 col5\" >0.814204</td>\n",
       "      <td id=\"T_75679_row21_col6\" class=\"data row21 col6\" >0.864188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row22\" class=\"row_heading level0 row22\" >17</th>\n",
       "      <td id=\"T_75679_row22_col0\" class=\"data row22 col0\" >2</td>\n",
       "      <td id=\"T_75679_row22_col1\" class=\"data row22 col1\" >0.500000</td>\n",
       "      <td id=\"T_75679_row22_col2\" class=\"data row22 col2\" >50</td>\n",
       "      <td id=\"T_75679_row22_col3\" class=\"data row22 col3\" >0.950000</td>\n",
       "      <td id=\"T_75679_row22_col4\" class=\"data row22 col4\" >0.840729</td>\n",
       "      <td id=\"T_75679_row22_col5\" class=\"data row22 col5\" >0.702134</td>\n",
       "      <td id=\"T_75679_row22_col6\" class=\"data row22 col6\" >0.911611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row23\" class=\"row_heading level0 row23\" >18</th>\n",
       "      <td id=\"T_75679_row23_col0\" class=\"data row23 col0\" >2</td>\n",
       "      <td id=\"T_75679_row23_col1\" class=\"data row23 col1\" >0.500000</td>\n",
       "      <td id=\"T_75679_row23_col2\" class=\"data row23 col2\" >100</td>\n",
       "      <td id=\"T_75679_row23_col3\" class=\"data row23 col3\" >0.700000</td>\n",
       "      <td id=\"T_75679_row23_col4\" class=\"data row23 col4\" >0.839957</td>\n",
       "      <td id=\"T_75679_row23_col5\" class=\"data row23 col5\" >0.736398</td>\n",
       "      <td id=\"T_75679_row23_col6\" class=\"data row23 col6\" >0.896762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row24\" class=\"row_heading level0 row24\" >31</th>\n",
       "      <td id=\"T_75679_row24_col0\" class=\"data row24 col0\" >4</td>\n",
       "      <td id=\"T_75679_row24_col1\" class=\"data row24 col1\" >0.500000</td>\n",
       "      <td id=\"T_75679_row24_col2\" class=\"data row24 col2\" >100</td>\n",
       "      <td id=\"T_75679_row24_col3\" class=\"data row24 col3\" >0.700000</td>\n",
       "      <td id=\"T_75679_row24_col4\" class=\"data row24 col4\" >0.838939</td>\n",
       "      <td id=\"T_75679_row24_col5\" class=\"data row24 col5\" >0.722386</td>\n",
       "      <td id=\"T_75679_row24_col6\" class=\"data row24 col6\" >0.943929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row25\" class=\"row_heading level0 row25\" >15</th>\n",
       "      <td id=\"T_75679_row25_col0\" class=\"data row25 col0\" >2</td>\n",
       "      <td id=\"T_75679_row25_col1\" class=\"data row25 col1\" >0.500000</td>\n",
       "      <td id=\"T_75679_row25_col2\" class=\"data row25 col2\" >10</td>\n",
       "      <td id=\"T_75679_row25_col3\" class=\"data row25 col3\" >0.950000</td>\n",
       "      <td id=\"T_75679_row25_col4\" class=\"data row25 col4\" >0.838758</td>\n",
       "      <td id=\"T_75679_row25_col5\" class=\"data row25 col5\" >0.711067</td>\n",
       "      <td id=\"T_75679_row25_col6\" class=\"data row25 col6\" >0.933248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row26\" class=\"row_heading level0 row26\" >37</th>\n",
       "      <td id=\"T_75679_row26_col0\" class=\"data row26 col0\" >4</td>\n",
       "      <td id=\"T_75679_row26_col1\" class=\"data row26 col1\" >1.000000</td>\n",
       "      <td id=\"T_75679_row26_col2\" class=\"data row26 col2\" >100</td>\n",
       "      <td id=\"T_75679_row26_col3\" class=\"data row26 col3\" >0.700000</td>\n",
       "      <td id=\"T_75679_row26_col4\" class=\"data row26 col4\" >0.835839</td>\n",
       "      <td id=\"T_75679_row26_col5\" class=\"data row26 col5\" >0.679777</td>\n",
       "      <td id=\"T_75679_row26_col6\" class=\"data row26 col6\" >0.953525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row27\" class=\"row_heading level0 row27\" >12</th>\n",
       "      <td id=\"T_75679_row27_col0\" class=\"data row27 col0\" >0</td>\n",
       "      <td id=\"T_75679_row27_col1\" class=\"data row27 col1\" >1.000000</td>\n",
       "      <td id=\"T_75679_row27_col2\" class=\"data row27 col2\" >100</td>\n",
       "      <td id=\"T_75679_row27_col3\" class=\"data row27 col3\" >0.950000</td>\n",
       "      <td id=\"T_75679_row27_col4\" class=\"data row27 col4\" >0.833749</td>\n",
       "      <td id=\"T_75679_row27_col5\" class=\"data row27 col5\" >0.749811</td>\n",
       "      <td id=\"T_75679_row27_col6\" class=\"data row27 col6\" >0.888775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row28\" class=\"row_heading level0 row28\" >38</th>\n",
       "      <td id=\"T_75679_row28_col0\" class=\"data row28 col0\" >4</td>\n",
       "      <td id=\"T_75679_row28_col1\" class=\"data row28 col1\" >1.000000</td>\n",
       "      <td id=\"T_75679_row28_col2\" class=\"data row28 col2\" >100</td>\n",
       "      <td id=\"T_75679_row28_col3\" class=\"data row28 col3\" >0.950000</td>\n",
       "      <td id=\"T_75679_row28_col4\" class=\"data row28 col4\" >0.832029</td>\n",
       "      <td id=\"T_75679_row28_col5\" class=\"data row28 col5\" >0.697083</td>\n",
       "      <td id=\"T_75679_row28_col6\" class=\"data row28 col6\" >0.916494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row29\" class=\"row_heading level0 row29\" >10</th>\n",
       "      <td id=\"T_75679_row29_col0\" class=\"data row29 col0\" >0</td>\n",
       "      <td id=\"T_75679_row29_col1\" class=\"data row29 col1\" >1.000000</td>\n",
       "      <td id=\"T_75679_row29_col2\" class=\"data row29 col2\" >50</td>\n",
       "      <td id=\"T_75679_row29_col3\" class=\"data row29 col3\" >0.950000</td>\n",
       "      <td id=\"T_75679_row29_col4\" class=\"data row29 col4\" >0.830719</td>\n",
       "      <td id=\"T_75679_row29_col5\" class=\"data row29 col5\" >0.799935</td>\n",
       "      <td id=\"T_75679_row29_col6\" class=\"data row29 col6\" >0.855765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row30\" class=\"row_heading level0 row30\" >14</th>\n",
       "      <td id=\"T_75679_row30_col0\" class=\"data row30 col0\" >2</td>\n",
       "      <td id=\"T_75679_row30_col1\" class=\"data row30 col1\" >0.500000</td>\n",
       "      <td id=\"T_75679_row30_col2\" class=\"data row30 col2\" >10</td>\n",
       "      <td id=\"T_75679_row30_col3\" class=\"data row30 col3\" >0.700000</td>\n",
       "      <td id=\"T_75679_row30_col4\" class=\"data row30 col4\" >0.828083</td>\n",
       "      <td id=\"T_75679_row30_col5\" class=\"data row30 col5\" >0.713911</td>\n",
       "      <td id=\"T_75679_row30_col6\" class=\"data row30 col6\" >0.907133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row31\" class=\"row_heading level0 row31\" >24</th>\n",
       "      <td id=\"T_75679_row31_col0\" class=\"data row31 col0\" >2</td>\n",
       "      <td id=\"T_75679_row31_col1\" class=\"data row31 col1\" >1.000000</td>\n",
       "      <td id=\"T_75679_row31_col2\" class=\"data row31 col2\" >100</td>\n",
       "      <td id=\"T_75679_row31_col3\" class=\"data row31 col3\" >0.700000</td>\n",
       "      <td id=\"T_75679_row31_col4\" class=\"data row31 col4\" >0.827999</td>\n",
       "      <td id=\"T_75679_row31_col5\" class=\"data row31 col5\" >0.697644</td>\n",
       "      <td id=\"T_75679_row31_col6\" class=\"data row31 col6\" >0.926803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row32\" class=\"row_heading level0 row32\" >8</th>\n",
       "      <td id=\"T_75679_row32_col0\" class=\"data row32 col0\" >0</td>\n",
       "      <td id=\"T_75679_row32_col1\" class=\"data row32 col1\" >1.000000</td>\n",
       "      <td id=\"T_75679_row32_col2\" class=\"data row32 col2\" >10</td>\n",
       "      <td id=\"T_75679_row32_col3\" class=\"data row32 col3\" >0.950000</td>\n",
       "      <td id=\"T_75679_row32_col4\" class=\"data row32 col4\" >0.826858</td>\n",
       "      <td id=\"T_75679_row32_col5\" class=\"data row32 col5\" >0.724016</td>\n",
       "      <td id=\"T_75679_row32_col6\" class=\"data row32 col6\" >0.871628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row33\" class=\"row_heading level0 row33\" >0</th>\n",
       "      <td id=\"T_75679_row33_col0\" class=\"data row33 col0\" >0</td>\n",
       "      <td id=\"T_75679_row33_col1\" class=\"data row33 col1\" >0.000000</td>\n",
       "      <td id=\"T_75679_row33_col2\" class=\"data row33 col2\" >10</td>\n",
       "      <td id=\"T_75679_row33_col3\" class=\"data row33 col3\" >0.700000</td>\n",
       "      <td id=\"T_75679_row33_col4\" class=\"data row33 col4\" >0.826702</td>\n",
       "      <td id=\"T_75679_row33_col5\" class=\"data row33 col5\" >0.772686</td>\n",
       "      <td id=\"T_75679_row33_col6\" class=\"data row33 col6\" >0.848113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row34\" class=\"row_heading level0 row34\" >1</th>\n",
       "      <td id=\"T_75679_row34_col0\" class=\"data row34 col0\" >0</td>\n",
       "      <td id=\"T_75679_row34_col1\" class=\"data row34 col1\" >0.500000</td>\n",
       "      <td id=\"T_75679_row34_col2\" class=\"data row34 col2\" >10</td>\n",
       "      <td id=\"T_75679_row34_col3\" class=\"data row34 col3\" >0.700000</td>\n",
       "      <td id=\"T_75679_row34_col4\" class=\"data row34 col4\" >0.825805</td>\n",
       "      <td id=\"T_75679_row34_col5\" class=\"data row34 col5\" >0.726745</td>\n",
       "      <td id=\"T_75679_row34_col6\" class=\"data row34 col6\" >0.864319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row35\" class=\"row_heading level0 row35\" >9</th>\n",
       "      <td id=\"T_75679_row35_col0\" class=\"data row35 col0\" >0</td>\n",
       "      <td id=\"T_75679_row35_col1\" class=\"data row35 col1\" >1.000000</td>\n",
       "      <td id=\"T_75679_row35_col2\" class=\"data row35 col2\" >50</td>\n",
       "      <td id=\"T_75679_row35_col3\" class=\"data row35 col3\" >0.700000</td>\n",
       "      <td id=\"T_75679_row35_col4\" class=\"data row35 col4\" >0.823071</td>\n",
       "      <td id=\"T_75679_row35_col5\" class=\"data row35 col5\" >0.780087</td>\n",
       "      <td id=\"T_75679_row35_col6\" class=\"data row35 col6\" >0.852172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row36\" class=\"row_heading level0 row36\" >6</th>\n",
       "      <td id=\"T_75679_row36_col0\" class=\"data row36 col0\" >0</td>\n",
       "      <td id=\"T_75679_row36_col1\" class=\"data row36 col1\" >0.500000</td>\n",
       "      <td id=\"T_75679_row36_col2\" class=\"data row36 col2\" >100</td>\n",
       "      <td id=\"T_75679_row36_col3\" class=\"data row36 col3\" >0.950000</td>\n",
       "      <td id=\"T_75679_row36_col4\" class=\"data row36 col4\" >0.819776</td>\n",
       "      <td id=\"T_75679_row36_col5\" class=\"data row36 col5\" >0.754644</td>\n",
       "      <td id=\"T_75679_row36_col6\" class=\"data row36 col6\" >0.860899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row37\" class=\"row_heading level0 row37\" >11</th>\n",
       "      <td id=\"T_75679_row37_col0\" class=\"data row37 col0\" >0</td>\n",
       "      <td id=\"T_75679_row37_col1\" class=\"data row37 col1\" >1.000000</td>\n",
       "      <td id=\"T_75679_row37_col2\" class=\"data row37 col2\" >100</td>\n",
       "      <td id=\"T_75679_row37_col3\" class=\"data row37 col3\" >0.700000</td>\n",
       "      <td id=\"T_75679_row37_col4\" class=\"data row37 col4\" >0.807175</td>\n",
       "      <td id=\"T_75679_row37_col5\" class=\"data row37 col5\" >0.677863</td>\n",
       "      <td id=\"T_75679_row37_col6\" class=\"data row37 col6\" >0.863955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75679_level0_row38\" class=\"row_heading level0 row38\" >36</th>\n",
       "      <td id=\"T_75679_row38_col0\" class=\"data row38 col0\" >4</td>\n",
       "      <td id=\"T_75679_row38_col1\" class=\"data row38 col1\" >1.000000</td>\n",
       "      <td id=\"T_75679_row38_col2\" class=\"data row38 col2\" >50</td>\n",
       "      <td id=\"T_75679_row38_col3\" class=\"data row38 col3\" >0.950000</td>\n",
       "      <td id=\"T_75679_row38_col4\" class=\"data row38 col4\" >0.803011</td>\n",
       "      <td id=\"T_75679_row38_col5\" class=\"data row38 col5\" >0.722423</td>\n",
       "      <td id=\"T_75679_row38_col6\" class=\"data row38 col6\" >0.901033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f8dc41da300>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline to test different invoke parameters\n",
    "class ParameterPipeline:\n",
    "    \"\"\"\n",
    "    Pipeline to evaluate LLM performance across different generation parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    llm : LLM\n",
    "        The language model wrapper.\n",
    "    evaluator : Evaluator\n",
    "        The evaluator for scoring answers.\n",
    "    dataset : Dataset\n",
    "        The dataset containing question/answer pairs.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    llm : LLM\n",
    "        The language model wrapper instance.\n",
    "    evaluator : Evaluator\n",
    "        The evaluator instance.\n",
    "    dataset : Dataset\n",
    "        The dataset instance.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, llm: LLM, evaluator: Evaluator, dataset: Dataset):\n",
    "        self.llm = llm\n",
    "        self.evaluator = evaluator\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def run_experiment(\n",
    "        self,\n",
    "        param_grid: dict,\n",
    "        num_samples: int = 5,\n",
    "        seed: int = 42,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Run experiments with different parameter combinations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        param_grid : dict\n",
    "            Dictionary where keys are parameter names and values are lists of values to test.\n",
    "            Can include \"number_of_shots\" to vary prompt examples.\n",
    "            Example: {\"temperature\": [0.5, 1.0], \"top_k\": [10, 50], \"number_of_shots\": [0, 2]}\n",
    "        num_samples : int, optional (default=5)\n",
    "            Number of question/answer pairs to use for averaging.\n",
    "        seed : int, optional (default=42)\n",
    "            Random seed for reproducibility.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Results table with columns: number_of_shots, parameter values,\n",
    "            avg_score, min_score, max_score.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        For temperature=0.0, duplicate combinations with same number_of_shots are skipped\n",
    "        since greedy decoding produces deterministic outputs.\n",
    "        \"\"\"\n",
    "        random.seed(seed)\n",
    "\n",
    "        # Extract number_of_shots from param_grid if present\n",
    "        number_of_shots_values = param_grid.pop(\"number_of_shots\", [0])\n",
    "\n",
    "        # Pre-generate prompts and entries for all number_of_shots values at once\n",
    "        questions = self.dataset.generate_multiple_prompts(\n",
    "            count=num_samples, number_of_shots=number_of_shots_values\n",
    "        )\n",
    "\n",
    "        # Generate all parameter combinations (excluding number_of_shots)\n",
    "        param_names = list(param_grid.keys())\n",
    "        param_values = list(param_grid.values())\n",
    "        invoke_combinations = list(itertools.product(*param_values))\n",
    "\n",
    "        # Create full combinations including number_of_shots\n",
    "        all_combinations = list(\n",
    "            itertools.product(number_of_shots_values, invoke_combinations)\n",
    "        )\n",
    "\n",
    "        results = []\n",
    "        # Track (number_of_shots, top_k) pairs already run for temperature 0\n",
    "        seen_temp0_combinations = set()\n",
    "\n",
    "        for number_of_shots, invoke_combo in tqdm(\n",
    "            all_combinations, desc=\"Testing parameter combinations\"\n",
    "        ):\n",
    "            invoke_params = dict(zip(param_names, invoke_combo))\n",
    "\n",
    "            # For temperature 0, skip top_k and top_p variation for same number_of_shots\n",
    "            if invoke_params.get(\"temperature\", 1.0) == 0.0:\n",
    "                key = number_of_shots\n",
    "                if key in seen_temp0_combinations:\n",
    "                    continue\n",
    "                seen_temp0_combinations.add(key)\n",
    "\n",
    "            scores = []\n",
    "\n",
    "            # Use pre-built prompts and entries\n",
    "            for prompt, main_entry in questions[number_of_shots]:\n",
    "                # Generate response with current invoke parameters\n",
    "                response = self.llm.invoke(prompt, **invoke_params)\n",
    "\n",
    "                # Evaluate response\n",
    "                score = self.evaluator.evaluate(response, main_entry.answer)\n",
    "                scores.append(score)\n",
    "\n",
    "            avg_score = sum(scores) / len(scores)\n",
    "\n",
    "            result = {\n",
    "                \"number_of_shots\": number_of_shots,\n",
    "                **invoke_params,\n",
    "                \"avg_score\": avg_score,\n",
    "                \"min_score\": min(scores),\n",
    "                \"max_score\": max(scores),\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "    def display_results(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Display results sorted by average score with color gradient.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            Results DataFrame from run_experiment.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pandas.io.formats.style.Styler\n",
    "            Styled DataFrame with rows sorted by avg_score (descending)\n",
    "            and a red-yellow-green background gradient on the avg_score column.\n",
    "        \"\"\"\n",
    "        df_sorted = df.sort_values(\"avg_score\", ascending=False)\n",
    "        return df_sorted.style.background_gradient(subset=[\"avg_score\"], cmap=\"RdYlGn\")\n",
    "\n",
    "\n",
    "# Define parameter grid to test (including number_of_shots)\n",
    "param_grid = {\n",
    "    \"number_of_shots\": [0, 2, 4],\n",
    "    \"temperature\": [0.0, 0.5, 1.0],\n",
    "    \"top_k\": [10, 50, 100],\n",
    "    \"top_p\": [0.7, 0.95],\n",
    "}\n",
    "\n",
    "# Create pipeline and run experiments\n",
    "pipeline = ParameterPipeline(llm, evaluator, ds)\n",
    "\n",
    "results_df = pipeline.run_experiment(\n",
    "    param_grid=param_grid,\n",
    "    num_samples=5,  # Use 5 question/answer pairs\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# Display results table\n",
    "pipeline.display_results(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
