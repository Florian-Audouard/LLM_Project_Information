# Projet LLM : Syst√®me de Questions-R√©ponses avec √âvaluation Automatique

## üìã Description du Projet

Ce projet impl√©mente un syst√®me de questions-r√©ponses bas√© sur un mod√®le de langage (LLM) avec une √©valuation automatique de la qualit√© des r√©ponses. L'objectif est d'explorer l'impact des diff√©rents param√®tres de g√©n√©ration et des techniques de prompting (zero-shot, few-shot) sur la qualit√© des r√©ponses g√©n√©r√©es.

---

## üèóÔ∏è Architecture du Code

### 1. Dataset de Questions-R√©ponses

J'ai cr√©√© un dataset de **15 questions-r√©ponses** sur le domaine de la **programmation informatique**. Les sujets couverts incluent :

-   Concepts fondamentaux (variables, fonctions, boucles)
-   Programmation orient√©e objet
-   D√©veloppement web (frontend/backend, API)
-   Outils de d√©veloppement (Git, SQL)
-   Bonnes pratiques (debugging, algorithmes)

### 2. Classes Principales

#### Classe `Data`

Conteneur simple pour stocker une paire question/r√©ponse avec les m√©thodes `__str__` et `__eq__` pour la repr√©sentation et la comparaison.

#### Classe `Dataset`

G√®re la collection de donn√©es avec les fonctionnalit√©s suivantes :

-   `get_random_entry()` : S√©lection al√©atoire d'une entr√©e
-   `generate_random_entries()` : G√©n√©ration d'entr√©es al√©atoires uniques
-   `build_prompt()` : Construction du prompt format√© avec les exemples few-shot
-   `generate_prompt()` : G√©n√©ration d'un prompt complet avec un nombre d'exemples sp√©cifi√©
-   `generate_multiple_prompts()` : G√©n√©ration de multiples prompts pour diff√©rents nombres de shots

#### Classe `LLM`

Wrapper pour le mod√®le de langage qui permet :

-   Chargement du tokenizer et du mod√®le
-   G√©n√©ration de r√©ponses avec param√®tres configurables (temp√©rature, top_k, top_p)
-   Nettoyage automatique des balises `<think>...</think>` dans les r√©ponses

#### Classe `Evaluator`

√âvaluateur utilisant la **similarit√© cosinus** entre les embeddings pour mesurer la qualit√© s√©mantique des r√©ponses.

#### Classe `ParameterPipeline`

Pipeline d'exp√©rimentation permettant de :

-   Tester toutes les combinaisons de param√®tres
-   Calculer les scores moyens, minimum et maximum
-   Afficher les r√©sultats avec un gradient de couleur

---

## ü§ñ Mod√®les Utilis√©s

| Mod√®le                                   | R√¥le          | Description                                           |
| ---------------------------------------- | ------------- | ----------------------------------------------------- |
| `Gensyn/Qwen2.5-1.5B-Instruct`           | LLM principal | Mod√®le de g√©n√©ration de texte l√©ger (1.5B param√®tres) |
| `sentence-transformers/all-MiniLM-L6-v2` | Embeddings    | Mod√®le pour calculer la similarit√© s√©mantique         |

---

## üìä M√©trique d'√âvaluation

### Similarit√© Cosinus des Embeddings

La m√©trique utilis√©e est la **similarit√© cosinus** entre les embeddings de la r√©ponse g√©n√©r√©e et de la r√©ponse de r√©f√©rence :

$$\text{score} = \cos(\theta) = \frac{\mathbf{A} \cdot \mathbf{B}}{|\mathbf{A}| \times |\mathbf{B}|}$$

O√π :

-   $\mathbf{A}$ = embedding de la r√©ponse g√©n√©r√©e
-   $\mathbf{B}$ = embedding de la r√©ponse de r√©f√©rence

**Interpr√©tation du score :**

-   **1.0** : R√©ponses s√©mantiquement identiques
-   **0.5-0.8** : R√©ponses partiellement correctes
-   **< 0.5** : R√©ponses peu pertinentes

Cette approche permet d'√©valuer la **qualit√© s√©mantique** plut√¥t qu'une correspondance exacte des mots.

---

## ‚öôÔ∏è Param√®tres Test√©s

### Param√®tres de Prompting

| Param√®tre         | Valeurs test√©es | Description                      |
| ----------------- | --------------- | -------------------------------- |
| `number_of_shots` | 0, 2, 4         | Nombre d'exemples dans le prompt |

### Param√®tres de G√©n√©ration

| Param√®tre     | Valeurs test√©es | Description                                        |
| ------------- | --------------- | -------------------------------------------------- |
| `temperature` | 0.0, 0.5, 1.0   | Contr√¥le la cr√©ativit√© (0 = d√©terministe)          |
| `top_k`       | 10, 50, 100     | Nombre de tokens candidats √† consid√©rer            |
| `top_p`       | 0.7, 0.95       | Seuil de probabilit√© cumulative (nucleus sampling) |

**Note importante :** Pour `temperature=0.0`, le mod√®le utilise le d√©codage glouton (greedy decoding), rendant les param√®tres `top_k` et `top_p` sans effet. Le code optimise cela en √©vitant les combinaisons redondantes.

---

## üî¨ M√©thodologie Exp√©rimentale

1. **G√©n√©ration des prompts** : Pour chaque nombre de shots diff√©rent, cinq prompts sont g√©n√©r√©s.
   Les prompts avec un nombre de shots plus √©lev√© reprennent la base de ceux g√©n√©r√©s pr√©c√©demment.

2. **G√©n√©ration des r√©ponses** : Le LLM g√©n√®re une r√©ponse pour chaque prompt
3. **√âvaluation** : Chaque r√©ponse est compar√©e √† la r√©f√©rence via similarit√© cosinus
4. **Agr√©gation** : Calcul de la moyenne, minimum et maximum des scores

### Structure du Prompt

```
QUESTION:
[Question exemple 1]
ANSWER:
[R√©ponse exemple 1]

QUESTION:
[Question exemple 2]
ANSWER:
[R√©ponse exemple 2]

QUESTION:
[Question √† r√©pondre]
ANSWER:
```

---

## üìà R√©sultats et Analyse

### Observations Attendues

1. **Impact du Few-Shot Learning** :

    - Le zero-shot (0 exemples) donne g√©n√©ralement des r√©sultats moins pr√©cis
    - Le few-shot (2-4 exemples) am√©liore la compr√©hension du format attendu

2. **Impact de la Temp√©rature** :

    - `temperature=0.0` : R√©ponses coh√©rentes mais parfois r√©p√©titives
    - `temperature=0.5` : Bon √©quilibre cr√©ativit√©/pr√©cision
    - `temperature=1.0` : Plus de variabilit√©, parfois moins pr√©cis

3. **Impact de top_k et top_p** :
    - Valeurs faibles : R√©ponses plus conservatrices
    - Valeurs √©lev√©es : Plus de diversit√© dans les r√©ponses

### Visualisation des R√©sultats

Le pipeline affiche un **tableau interactif** avec :

-   Gradient de couleur (rouge ‚Üí jaune ‚Üí vert) sur le score moyen
-   Tri par score d√©croissant
-   Scores min/max pour √©valuer la variance

---

## üéØ Conclusion

Ce projet d√©montre l'importance du **r√©glage des hyperparam√®tres** dans les syst√®mes de g√©n√©ration de texte :

1. **Le few-shot learning** am√©liore significativement la qualit√© des r√©ponses en fournissant un contexte et un format de r√©ponse attendu au mod√®le.

2. **La temp√©rature** est le param√®tre le plus impactant : une valeur de 0 garantit la reproductibilit√©, tandis que des valeurs plus √©lev√©es introduisent de la variabilit√©.

3. **L'√©valuation par embeddings** offre une mesure robuste de la similarit√© s√©mantique, plus pertinente qu'une simple comparaison de cha√Ænes de caract√®res.

4. **L'automatisation des tests** via le `ParameterPipeline` permet d'explorer efficacement l'espace des hyperparam√®tres et d'identifier les configurations optimales.

---

## üìÅ Structure du Projet

```
LLM_Project_Information/
‚îú‚îÄ‚îÄ main.ipynb      # Notebook principal avec tout le code
‚îî‚îÄ‚îÄ README.md       # Documentation du projet
```

---

## üõ†Ô∏è D√©pendances

```python
torch                    # Framework deep learning
transformers             # Mod√®les Hugging Face
sentence-transformers    # Embeddings de phrases
pandas                   # Manipulation de donn√©es
tqdm                     # Barres de progression
```

---

## üöÄ Ex√©cution

1. Ex√©cuter les cellules d'installation des d√©pendances
2. Charger les mod√®les (LLM et embeddings)
3. Lancer le pipeline d'exp√©rimentation
4. Analyser le tableau de r√©sultats g√©n√©r√©

---

_Projet r√©alis√© dans le cadre du cours sur les Large Language Models (LLM)_
